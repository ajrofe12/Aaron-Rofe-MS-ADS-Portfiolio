# Aaron Rofe Blog Post - M.S. in Applied Data Science Program

### Intro
When I started the M.S. in Applied Data Science program at Syracuse University, I felt confident in my foundation from my Sport Analytics undergrad degree that I also got here at Syracuse, but I knew I still had room to grow to make me a more attractive candidate when I wanted to look for a job. I could work with data, build more basic models, and communicate results, but I wanted to learned the broader applciations of  data science beyond sports and understand how analytics plays a role in other fields like business, healthcare, finance, and technology. I came into the program knowing the basics of the data data pipeline, but I wanted to learn how to manage an entire end-to-end workflow—from collecting raw data and structuring it properly to modeling, interpreting results, and ultimately communicating insights effectively.

### What I expected to learn
Coming into the program, I expected to learn more advanced data science techniques and deep the skills that I had learned in undergrad. I wanted to learn how to work with large and more complex datasets, improve my programming skills in languages such as Python, R and SQL, and improve my knowledge with machine learning algorithms that I learned in undergrad such as gradient boosting. I was also hoping to learn more about database design, data communication, and how to evaluate models in real-world contexts rather than just in classroom examples. Overall, I hoped the program would broaden my skills and prepare me for various analytical tasks faced in a variety of industries.

### What I learned in the Program
The program not only met my expectations but exceeded them. Instead of just learning new tools, I learned how the entire data science process fits together - how decisions made during data collection affect modeling down the line, how preprocessing choices influence interpretability, and how communication impacts stakeholder decision-making. Throughout the program, I encountered many different tiles of problems across courses like IST 659 (Database management), IST 687 (Intro to Applied Data Science), IST 707 (Machine Learning), IST 737 (Information Visualization), SCM 651 (Business Analytics) and MBC 638 (Data Analysis & Decision Making).

By working on these projects, I gained real experience cleaning messy datasets, engineering features, tuning models, interpreting output, and building tools that others can use. I strengthened my programming abilities in both R and Python and learned to choose the right language depending on the problem. One of my biggest takeaways was from IST 707—the Machine Learning course—where I realized how much more efficient and powerful Python is for machine learning workflows compared to R. Courses across the program helped me understand not only the technical concepts but also the practical and ethical considerations involved in real-world analytics. By the time I finished, I felt confident working through an entire project from start to finish.

## Achieving Each Learning Outcome

### 1. Collect, store, and access data by identifying and leveraging applicable technologies
I developed strong skills in gathering and managing data through several courses in the program. In IST 652, I am currently working on a project involving fantasy football, which involved collecting data from the Sleeper API using Python. I am also currently working on a final project in IST 691, the deep learning class, where I had to use python to help collect audio data from the FMA dataset, which contained metadata of 30-second audio clips and the actual mp3 files. For IST 707, my group and I collected data from the ERA5-Land Dataset and the Federal Reserve Bank of St. Louis to get climate data and commodity pricing data for 7 common global commodities and built a pipeline in python for full preprocessing and modeling. Lastly, for the IST 687 final project, I used R to work with a massive dataset of household energy usage and take a subset of the data so it could be used to load faster into the shiny app I made. These experiences taught me how to handle data from many different sources and formats.

### 2. Create actionable insight across a range of contexts (e.g. societal, business, political), using data and the full data science life cycle
Many of the classes I took required me to follow the data science lifecycle: define a question, collect and clean data, prepare features, build models for analysis, and interpret the results. Currently for IST 652, even though my group isn't planning on building a predictive model for our analysis, we still had to formulate our research questions, collect and clean data from an external API, and explore scoring behavior in fantasy football. In IST 687, I used the lifecycle from start to finish - cleaning the dataset, performing exploratory analysis, building several predictive models, evaluating accuracy through confusion matrices and performance metrics, and delivering the results in an interative shiny app. IST 686 required building both frequentist and Bayesian linear models, which gave me a deeper understanding of how model assumptions influence outcomes.

The Climate-Commodity ML project for IST 707 was the most complex example of applying the lifecycle. We explored relationships across dozens of climate variables, handled missingness and seasonal trends, engineered features, built ML models, evaluated results, and then re-designed the entire approach once we discovered that COVID-era shocks broke the model. This experience showed me that the lifecycle isn’t always linear—sometimes, you have to revisit earlier stages when unexpected results arise.

### 3. Apply visualization and predictive models to help generate actionable insight
Visualization became very important for me during the program. The information visualization course, IST 737, helped me significantly improve my Tableau skills and understand how to design visuals that are both informative and intuitive to present to all audiences, especially non-technical ones. I have also used visualizations in my other projects such as time series plots, confusion matrices, and variable importance plots such as the ones in the climate-commodity project and the energy usage shiny app. I also gained experience with many predictive modeling techniques in IST 707 such as gradient boost, random forest, SVMs, Logistic Regression, clustering, dimensionality reduction. Although it wasn't part of the masters program, I've also used some of these techniques in undergrad in my senior thesis paper and in two case competitions I competed in during my junior year of undergad in February and March 2024. Together, these skills helped me learn to combine visuals and models to produce insights that are both comprehensive and understandable. 

### 4. Use programming languages such as R and Python to support the generation of actionable insight
I used Python, R and SQL a lot throughout the program and greatly improved my programming abilities in all three. I used R in the energy usage shiny app, in my final project for cleaning and analysis in IST 686, and I learned a lot of R in IST 687 from tasks such as basic analysis in tidyverse, visualizations, linear modeling, machine learning, association rules mining, text mining and shiny apps. Python was essential in IST 707 for learning different algorithms in class and for thre climate-commodity project where I used it for data processing, feature engineering, visualization and modeling. Python has alo been used in the deep learning class IST 691 that I'm taking right now where I've learned to code different kinds of neural networks. I've also used python this semester in IST 652 for various intro to python things such as pandas and numpy, and I'm using it currently on the Fantasy Football final project. Lastly, I also used a lot of SQL in IST 659, where I learned to design and implement full relational databased from scratch. Collectively, these languages gave me a well-rounded technical toolbox. 

### 5. Communicate insights gained via visualization and analytics to a broad range of audiences (including project sponsors and technical team leads)
I learned how important communication is in this course, and visualization is a major part of communicating insights to technical and non-technical audiences. In IST 737, I learned more about Tableau and effective ways to make visualizations that present a lot of important information, while also being intuitive to understand. Shiny apps are a great interactive dashboard for users to be presented with information, and the energy usage app I made in IST 687 allowed me to explain the model preditctions in a clear, user-friendly format. The IST 659 hospital database project required presenting the logical and conceptual models which allows audiences to understand the relationships between tables in an easier to understand way. The climate-commodity project required writing clear documentations to explain the relationships between variables and the limitations of the original model and why we had to pivot to the MMM to account for the economic shocks of COVID-19. 

### 6. Apply ethics in the development, use and evaluation of data and predictive models (e.g., fairness, bias, transparency, privacy)
IST 691, Responsible AI, shaped my understanding of fairness, bias, privacy, and transparency in AI and predictive modeling. I learned how ethical issues can appear long before the model is built from data collection to feature engineering and continue through deployment. These lessons showed up in my projects as well such as the energy usage shiny app, where we removed certain variables to prevent leakage and reduced biased predictions. In the climate-commodity project for training we separated X and variabesl to prevent leake as well, and also accounted for extreme anomalies like COVID-era price spikes. Across the program, I learned to evaluate models not just by performance metrics but also by their ethical implications.


## How Three Key Projects Contributed to my Education
### Climate-Commodity Machine Learning Project
This was my final project for the applied machine learning class IST 707. For this project my group and I collected data from the ERA5-Land dataset and the federal reserve bank of St. Louis to examine the relationship between climate variables and the price of seven common global commodities such as coffee, corn and rice just to name a few. For this project we had to clean and merge the datasets together, engineer features, build predictive mdoels, and interpret the results. It was a technically challenging modelling process, as for the first few years the predicted and actual price of the commodities had a reasonable residual value, then after 2020, the residuals drastically increased due to economic shocks caused by the  COVID-19 pandemic. This caused us to implement a two part Markovian Momentum Model which included a base climate model (ex: random forest or linear regression) as well as a logistic regression to predict the probability of being in a shock regime based on momentum indicators and shipping prices. 

### Emergency Hospital Transportation Database
In IST 659, I designed a relational database system to support emergency hospital transportation workflows. This project strengthened my understanding of relational database architecture, entity relationships, and SQL. Building the conceptual and logical models helped me appreciate how much planning must occur before any analytics can be built on top of a system. From designing tables to enforcing constraints, implementing triggers, and writing structured queries, I learned how backend systems support the accuracy and efficiency of front-end analytics. The project taught me the importance of organization and structure in data systems, which is foundational for any form of analysis.

### Residential Energy Usage Shiny App
In IST 687, I built an interactive Shiny app using R that predicted household energy usage levels. The project required me to work with a massive dataset of over 8 million rows, engineer features, build predictive models—including ordered logit, ordered probit, and Random Forest—and evaluate their performance. After determining that the Random Forest model performed best, I integrated it into the Shiny app, which allowed users to explore the predictions interactively. This project showed me how to package a model into a tool that others can actually use, which is one of the most important skills in applied data science. This project was also great practice for me in making a shiny app, although I had built a few prior to this, it was still good practice for using a very powerful tool.

## Outside the classroom
I didn't do a data science/data analytics during the course of the program, but during my undergrad years I did internships in analytics in summer 2023 and 2024. In summer 2023, I was a Trackman data and operations intern for the Upper Valley Nighthawks of the New England Collegiate Baseball League. Trackman is a rader-based ball-trackin system used across college and professional baseball to capture detailed pitch-by-pich data such as velocity, spin rates, exit velocity, pitch movement and launch angle. My role involved operating the system during games and communicating with coaches about player performance metrics. This experience strengthed my ability to work in a fast-paced environment with coaches and taught me the importance of data quality. The following summer, in 2024, I continued in baseball analytics and worked as an On-Site Data Collection and data analyst intern for the Hamptons Collegiate Baseball League. In this role I colelcted in-game data and then used the data to analyze player performance trneds and create reports for coaches to guide lineup decisions, scouting and player development. This was another experience that helped me improve on my data analysis skills and my ability to translate my findings into practical recommendations for non-technical audiences for coaches. 

Even though these internships took place prior to the master's program, they influenced how I approached my graduate coursework and gave me something to build on during my time in the program. They motivated me to refine my technical foundation, learn more sophisticated modeling techniques, and strenghten my coding skills so I could apply them in a professional setting. 

### Favorite Class
My favorite course in the program was IST 707, Applied Machine Learning. It introduced a wide range of algorithms and techniques that I had never worked with before and provided a lot of depth that I was hoping to gain when I enrolled into the program. The class was challenging, which simultaneously made it very rewarding and it was the course that highly influenced my interest in machine learning.

### Best Part of the Program
The best part of the M.S. in Applied Data Science program was the opportunity to expand my skillset through meaningful, hands-on projects. Every course contributed something valuable, and by the end of the program I had learned a lot and had a full portfolio that reflects my analytical abailities that also helps me get a job in the future. The program made me more confident and prepared for the job market by pushing me to apply what I learned in practical ways.

### Biggest Surprise
Honestly, I don't believe there were too many surprises in the program because everything I learned felt like a natural extension of what I was already exposed to in my Sport Analytics undergrad. I came in expecting to deepen my skills and learn new techniques and that's exactly what happened. The niggest surprise was realizing just how much more there was to learn. Even though I had a solid foundation, the program showed me how many additional layers there are in data science such as data engineering, modeling nuances, ethical considerations, and full end-to-end workflows. It made me appreciate how much more complex and comprehensive the field is than what I saw in undergrad. 

### Final Thoughts
As I look back on my time in the Applied Data Science program, I feel grateful for how much I’ve grown. The program challenged me, exposed me to new tools and concepts, and helped me become a far more capable analyst than I was when I entered. The combination of coursework, hands-on projects, and continued learning outside the classroom helped me build a strong portfolio and the confidence to pursue data-focused roles. This program helped me bridge the gap between being someone who can analyze data and someone who can manage an entire analytics workflow. I now feel ready to apply these skills in a professional setting, and I’m excited for the next chapter of my career.
